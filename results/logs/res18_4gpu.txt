# m=4, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,2.2702,0.2589,6882.03,7.25
2,1.6333,0.3929,7514.59,6.64
3,1.4813,0.4569,7334.19,6.81
4,1.3097,0.5291,7249.01,6.89
5,1.1873,0.5807,7340.98,6.80
6,1.1005,0.6136,7658.99,6.52
7,1.0436,0.6357,7610.07,6.56
8,0.9833,0.6557,7906.51,6.31
9,0.9564,0.6693,7664.48,6.51
10,0.9199,0.6830,7755.21,6.44
11,0.8970,0.6906,7914.78,6.31
12,0.8735,0.6976,7447.45,6.70
13,0.8596,0.7045,7661.03,6.52
14,0.8473,0.7088,7653.74,6.52
15,0.8318,0.7154,7436.12,6.71

# m=4, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,2.1683,0.3035,12740.16,3.92
2,1.5497,0.4389,14036.53,3.56
3,1.3265,0.5180,14034.88,3.56
4,1.1940,0.5708,14338.76,3.48
5,1.0974,0.6117,13126.39,3.80
6,1.0095,0.6404,14634.13,3.41
7,0.9493,0.6639,13198.76,3.78
8,0.8913,0.6847,14625.60,3.41
9,0.8507,0.7049,13948.55,3.58
10,0.8202,0.7124,13623.73,3.66
11,0.7918,0.7254,14075.40,3.55
12,0.7625,0.7365,13988.73,3.57
13,0.7409,0.7419,13727.18,3.64
14,0.7255,0.7492,13626.50,3.66
15,0.7087,0.7533,13886.05,3.59

# m=4, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,2.3385,0.2757,20410.03,2.43
2,1.6428,0.4160,24431.20,2.03
3,1.4526,0.4791,24446.96,2.03
4,1.3276,0.5270,24346.70,2.04
5,1.1941,0.5769,23556.07,2.11
6,1.0890,0.6117,24547.16,2.02
7,1.0206,0.6382,24378.46,2.04
8,0.9453,0.6658,24632.34,2.02
9,0.9003,0.6806,24548.44,2.02
10,0.8648,0.6948,24307.70,2.04
11,0.8222,0.7128,24509.70,2.03
12,0.7908,0.7209,24563.59,2.02
13,0.7517,0.7364,24481.77,2.03
14,0.7348,0.7417,24641.86,2.02
15,0.7063,0.7517,24535.39,2.02

# m=4, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,2.8895,0.2030,24410.73,2.01
2,1.8432,0.3298,31548.47,1.56
3,1.6898,0.3944,31173.03,1.58
4,1.5676,0.4337,31347.72,1.57
5,1.4376,0.4773,31482.42,1.56
6,1.3348,0.5197,31378.11,1.57
7,1.2294,0.5604,31391.88,1.57
8,1.1499,0.5923,31432.91,1.56
9,1.0807,0.6174,31597.89,1.56
10,1.0189,0.6378,31377.49,1.57
11,0.9677,0.6577,31409.42,1.56
12,0.9201,0.6714,30999.02,1.59
13,0.9024,0.6819,31057.63,1.58
14,0.8686,0.6916,31523.03,1.56
15,0.8152,0.7130,31419.19,1.56

# m=4, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,2.7343,0.2022,24958.47,1.97
2,1.7721,0.3605,32768.02,1.50
3,1.5824,0.4307,32215.06,1.53
4,1.4430,0.4806,33104.80,1.48
5,1.3280,0.5224,31788.53,1.55
6,1.2192,0.5661,33182.77,1.48
7,1.1464,0.5920,31695.24,1.55
8,1.0875,0.6122,32378.67,1.52
9,1.0287,0.6308,32379.64,1.52
10,0.9784,0.6552,33005.01,1.49
11,0.9254,0.6725,33106.15,1.48
12,0.8994,0.6805,33455.18,1.47
13,0.8499,0.6990,32908.92,1.49
14,0.8195,0.7088,33493.66,1.47
15,0.7968,0.7187,33160.18,1.48

# m=8, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,2.2841,0.2582,4033.85,12.38
2,1.6799,0.3781,4131.29,12.08
3,1.5123,0.4496,4020.92,12.42
4,1.3425,0.5186,4327.12,11.54
5,1.2279,0.5660,4300.39,11.61
6,1.1467,0.5989,4276.06,11.67
7,1.0794,0.6248,4288.17,11.64
8,1.0337,0.6424,4326.69,11.54
9,0.9922,0.6578,4250.27,11.75
10,0.9558,0.6718,4145.37,12.04
11,0.9315,0.6784,4344.27,11.49
12,0.9141,0.6879,4362.57,11.44
13,0.8925,0.6949,4324.91,11.54
14,0.8738,0.6996,4363.95,11.44
15,0.8620,0.7057,4286.52,11.65

# m=8, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,2.2213,0.2932,7343.59,6.80
2,1.5689,0.4302,7865.62,6.35
3,1.3783,0.5051,8214.06,6.08
4,1.2219,0.5645,8164.20,6.11
5,1.1369,0.5960,7949.09,6.28
6,1.0325,0.6363,8102.74,6.16
7,0.9798,0.6557,8021.62,6.22
8,0.9247,0.6761,8191.09,6.09
9,0.8832,0.6932,7869.64,6.34
10,0.8472,0.7065,8220.38,6.07
11,0.8084,0.7214,8059.76,6.19
12,0.7998,0.7233,7904.52,6.32
13,0.7751,0.7330,7740.13,6.45
14,0.7516,0.7401,8430.79,5.92
15,0.7346,0.7474,8071.47,6.18

# m=8, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,2.7113,0.2262,12665.76,3.92
2,1.7808,0.3671,14498.41,3.43
3,1.5464,0.4414,15359.08,3.23
4,1.3932,0.4974,15134.05,3.28
5,1.2696,0.5438,15419.66,3.22
6,1.1661,0.5839,15541.58,3.20
7,1.0732,0.6207,14990.89,3.31
8,1.0019,0.6427,15009.11,3.31
9,0.9386,0.6705,14989.25,3.31
10,0.8876,0.6854,14651.48,3.39
11,0.8395,0.7041,14991.77,3.31
12,0.8001,0.7192,15155.86,3.28
13,0.7786,0.7283,15685.22,3.17
14,0.7522,0.7385,15670.20,3.17
15,0.7257,0.7479,14976.91,3.32

# m=8, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,2.4224,0.2685,19496.62,2.52
2,1.8318,0.3845,23408.08,2.10
3,1.7658,0.4061,23764.62,2.07
4,1.5080,0.4632,23639.40,2.08
5,1.3940,0.5111,23742.29,2.07
6,1.2818,0.5486,23680.54,2.08
7,1.1611,0.5877,23715.66,2.07
8,1.0930,0.6175,23768.18,2.07
9,1.0246,0.6363,23785.61,2.07
10,0.9637,0.6599,23757.53,2.07
11,0.9168,0.6776,23795.56,2.07
12,0.8757,0.6895,23675.49,2.08
13,0.8377,0.7030,23738.33,2.07
14,0.8130,0.7156,23764.24,2.07
15,0.7750,0.7285,23633.68,2.08

# m=8, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,2.9744,0.1967,22897.45,2.15
2,1.7855,0.3471,29280.17,1.68
3,1.6033,0.4179,29397.41,1.67
4,1.5028,0.4613,29426.43,1.67
5,1.4218,0.4934,29332.12,1.68
6,1.3375,0.5235,29364.22,1.67
7,1.2282,0.5598,29116.97,1.69
8,1.1500,0.5934,29296.86,1.68
9,1.1000,0.6103,29389.15,1.67
10,1.0428,0.6258,29282.05,1.68
11,0.9827,0.6493,29136.82,1.69
12,0.9446,0.6622,29399.93,1.67
13,0.9164,0.6743,29321.76,1.68
14,0.9149,0.6785,29325.34,1.68
15,0.8541,0.6980,28824.02,1.71
