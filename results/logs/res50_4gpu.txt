
# m=4, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,4.9506,0.1541,3390.23,14.72
2,2.0753,0.2091,3504.56,14.24
3,1.9585,0.2441,3570.36,13.98
4,1.8941,0.2732,3559.56,14.02
5,1.7810,0.3294,3703.91,13.48
6,1.6922,0.3730,3584.50,13.93
7,1.6291,0.4013,3704.66,13.47
8,1.5661,0.4275,3776.35,13.22
9,1.5169,0.4513,3598.88,13.87
10,1.4529,0.4760,3763.43,13.26
11,1.4079,0.4912,3662.86,13.63
12,1.3497,0.5152,3705.54,13.47
13,1.2998,0.5345,3775.37,13.22
14,1.2464,0.5571,3625.84,13.77
15,1.1827,0.5826,3777.38,13.22

# m=4, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,5.7537,0.1171,5417.53,9.21
2,2.3166,0.1724,5712.57,8.74
3,1.9904,0.2545,5740.24,8.70
4,1.8968,0.2867,5733.82,8.71
5,1.7863,0.3345,5742.34,8.69
6,1.6781,0.3823,5726.64,8.72
7,1.6112,0.4127,5746.22,8.69
8,1.5363,0.4394,5733.35,8.71
9,1.4698,0.4645,5728.92,8.71
10,1.4266,0.4818,5734.22,8.71
11,1.3593,0.5074,5716.83,8.73
12,1.3080,0.5300,5733.38,8.71
13,1.2608,0.5472,5737.46,8.70
14,1.2266,0.5607,5721.43,8.73
15,1.2091,0.5669,5725.64,8.72

# m=4, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,7.7655,0.1195,6861.20,7.24
2,2.9222,0.1692,7353.08,6.75
3,2.3602,0.2201,7381.11,6.73
4,2.0846,0.2751,7369.95,6.74
5,1.8970,0.3257,7401.44,6.71
6,1.8201,0.3500,7374.42,6.73
7,1.7260,0.3716,7394.11,6.72
8,1.6760,0.3843,7358.29,6.75
9,1.6275,0.4031,7401.82,6.71
10,1.5983,0.4180,7359.87,6.75
11,1.5596,0.4291,7342.09,6.76
12,1.5302,0.4458,7390.18,6.72
13,1.4919,0.4574,7361.62,6.75
14,1.4557,0.4678,7393.25,6.72
15,1.4207,0.4851,7377.40,6.73

# m=4, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,10.5838,0.1016,7693.94,6.39
2,3.1371,0.1036,8277.41,5.94
3,2.6485,0.1069,8288.51,5.93
4,2.5283,0.1290,8292.97,5.93
5,2.3395,0.1603,8312.19,5.91
6,2.2878,0.2005,8307.78,5.92
7,2.1575,0.2266,8279.31,5.94
8,2.0762,0.2547,8306.57,5.92
9,2.0104,0.2865,8306.36,5.92
10,1.9123,0.2978,8330.72,5.90
11,1.8294,0.3228,8317.30,5.91
12,1.7596,0.3469,8308.12,5.92
13,1.7735,0.3602,8316.29,5.91
14,1.7126,0.3773,8299.39,5.92
15,1.6500,0.3979,8282.83,5.93

# m=4, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,8.9585,0.1034,9695.73,5.07
2,3.3084,0.1074,12295.57,4.00
3,2.7258,0.1093,12247.50,4.01
4,2.6062,0.1406,12410.12,3.96
5,2.7162,0.1468,12289.25,4.00
6,2.5574,0.1641,12408.08,3.96
7,2.5476,0.1779,12451.00,3.95
8,2.4592,0.1920,12204.12,4.03
9,2.3730,0.2156,12447.22,3.95
10,2.4171,0.2404,12275.05,4.00
11,2.2766,0.2569,12410.33,3.96
12,2.1452,0.2750,12301.67,4.00
13,2.1264,0.2933,12367.86,3.97
14,2.0370,0.3128,12373.23,3.97
15,2.0601,0.2970,12218.75,4.02

# m=8, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,6.4084,0.1059,1863.16,26.79
2,2.3007,0.1048,1949.88,25.60
3,2.3002,0.1074,1964.04,25.42
4,2.2972,0.1137,1940.23,25.73
5,2.2961,0.1173,1925.81,25.92
6,2.1026,0.1769,1954.69,25.54
7,2.0011,0.2056,1954.20,25.55
8,1.8897,0.2673,1950.13,25.60
9,1.8759,0.2874,1965.84,25.39
10,1.8178,0.3177,1925.92,25.92
11,1.7511,0.3501,1843.49,27.08
12,1.6267,0.4023,1916.86,26.04
13,1.5358,0.4368,1905.10,26.20
14,1.4650,0.4697,1912.33,26.10
15,1.3833,0.5036,1973.60,25.29

# m=8, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,8.0412,0.1411,3710.69,13.45
2,2.1573,0.1979,3934.94,12.69
3,2.0357,0.2456,3800.86,13.13
4,1.9092,0.2995,3852.43,12.96
5,1.8062,0.3363,3948.12,12.64
6,1.7337,0.3631,3949.58,12.64
7,1.6684,0.3867,3938.87,12.67
8,1.6171,0.4085,3889.85,12.83
9,1.5622,0.4287,3866.79,12.91
10,1.5160,0.4493,3857.03,12.94
11,1.4759,0.4644,3972.58,12.57
12,1.4336,0.4816,3968.71,12.58
13,1.3908,0.4988,3954.42,12.62
14,1.3522,0.5140,3761.79,13.27
15,1.3019,0.5313,3905.03,12.78

# m=8, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,10.8730,0.1170,5406.80,9.19
2,2.7095,0.1418,5671.22,8.76
3,2.3059,0.1625,5618.88,8.84
4,2.2184,0.1802,5674.29,8.75
5,2.1199,0.2022,5683.94,8.74
6,2.0187,0.2321,5675.58,8.75
7,1.9452,0.2698,5649.45,8.79
8,1.8614,0.3017,5276.40,9.41
9,1.8001,0.3259,5605.31,8.86
10,1.7484,0.3474,5667.61,8.76
11,1.7107,0.3645,5634.91,8.81
12,1.6704,0.3838,5675.87,8.75
13,1.6383,0.3954,5668.87,8.76
14,1.6020,0.4102,5659.66,8.78
15,1.5644,0.4276,5661.43,8.77

# m=8, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,9.4246,0.0992,6795.38,7.23
2,2.9669,0.1018,7263.95,6.77
3,2.7830,0.1050,7272.71,6.76
4,2.6365,0.1125,7260.55,6.77
5,2.6142,0.1359,6895.60,7.13
6,2.3947,0.1884,7279.47,6.75
7,2.2237,0.2312,7267.57,6.76
8,2.0265,0.2634,7285.71,6.75
9,1.9639,0.2925,7264.53,6.77
10,1.8435,0.3281,7276.99,6.75
11,1.7842,0.3451,7292.32,6.74
12,1.7097,0.3679,7284.10,6.75
13,1.6576,0.3876,7268.09,6.76
14,1.6072,0.4077,7270.95,6.76
15,1.5751,0.4235,7288.40,6.74

# m=8, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,14.5832,0.1099,7496.71,6.56
2,5.8223,0.1294,8161.68,6.02
3,3.3451,0.1742,8132.09,6.04
4,2.9788,0.1888,8149.25,6.03
5,2.8210,0.1977,8160.79,6.02
6,2.8484,0.2009,8144.91,6.03
7,2.8010,0.2095,8128.03,6.05
8,2.4227,0.2179,8142.93,6.04
9,2.5011,0.2168,8171.10,6.02
10,2.3682,0.2234,8125.50,6.05
11,2.4113,0.2223,8100.83,6.07
12,2.3389,0.2133,8129.15,6.05
13,2.2322,0.2254,8072.94,6.09
14,2.3295,0.2364,7625.82,6.45
15,2.2674,0.2515,8089.10,6.08
