
# m=4, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,4.9443,0.1300,3962.87,12.60
2,2.1518,0.1855,4012.10,12.44
3,1.9948,0.2293,4013.84,12.44
4,1.8880,0.2734,3988.89,12.51
5,1.8083,0.3182,3990.69,12.51
6,1.7398,0.3530,3885.55,12.85
7,1.6647,0.3874,3942.16,12.66
8,1.6102,0.4086,3948.31,12.64
9,1.5741,0.4229,3872.52,12.89
10,1.5182,0.4471,3871.85,12.89
11,1.4436,0.4738,3896.63,12.81
12,1.4366,0.4835,4028.95,12.39
13,1.3034,0.5337,3859.81,12.93
14,1.2404,0.5608,3935.15,12.69
15,1.1759,0.5846,4018.69,12.42

# m=4, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,8.4052,0.1152,5683.59,8.78
2,2.3384,0.1825,5920.49,8.43
3,2.0338,0.2328,5941.03,8.40
4,1.8825,0.2903,5949.57,8.39
5,1.7786,0.3344,5940.09,8.40
6,1.6900,0.3733,5934.25,8.41
7,1.5934,0.4111,5908.00,8.45
8,1.5175,0.4447,5915.14,8.44
9,1.4489,0.4705,5924.63,8.43
10,1.3911,0.4931,5915.54,8.44
11,1.3297,0.5189,5909.03,8.45
12,1.2744,0.5401,5917.17,8.44
13,1.2254,0.5596,5933.82,8.41
14,1.1664,0.5797,5939.30,8.41
15,1.1234,0.5979,5907.35,8.45

# m=4, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,6.3890,0.1026,7242.89,6.86
2,2.8332,0.1270,7659.72,6.48
3,2.4731,0.1651,7689.66,6.46
4,2.1939,0.2279,7653.57,6.49
5,1.9638,0.2787,7664.07,6.48
6,1.8423,0.3301,7668.33,6.48
7,1.7434,0.3596,7666.39,6.48
8,1.6572,0.3938,7684.49,6.46
9,1.6071,0.4115,7674.63,6.47
10,1.5596,0.4353,7666.89,6.48
11,1.5097,0.4510,7655.95,6.49
12,1.4611,0.4673,7675.86,6.47
13,1.4215,0.4847,7652.81,6.49
14,1.3794,0.4986,7700.50,6.45
15,1.3489,0.5114,7666.14,6.48

# m=4, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,7.2140,0.1048,7412.62,6.63
2,3.5171,0.1148,8666.20,5.67
3,3.0744,0.1252,8657.33,5.68
4,2.7676,0.1572,8614.79,5.71
5,2.5899,0.1971,8624.42,5.70
6,2.4518,0.2367,8607.85,5.71
7,2.1442,0.2945,8616.44,5.70
8,2.1298,0.3282,8647.18,5.68
9,1.9523,0.3524,8634.30,5.69
10,1.8693,0.3844,8584.93,5.73
11,1.7782,0.4042,8605.36,5.71
12,1.6709,0.4272,8619.97,5.70
13,1.6251,0.4391,8637.14,5.69
14,1.5468,0.4583,8622.05,5.70
15,1.5263,0.4674,8612.22,5.71

# m=4, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,10.4101,0.1036,11912.74,4.13
2,4.7494,0.1018,13258.98,3.71
3,3.9233,0.1139,13357.00,3.68
4,2.8782,0.1266,13267.75,3.70
5,3.1997,0.1420,13302.22,3.70
6,2.9715,0.1484,13376.50,3.67
7,2.9190,0.1608,13325.45,3.69
8,2.5764,0.1732,13281.18,3.70
9,2.3326,0.1837,13361.01,3.68
10,2.4799,0.1942,13325.46,3.69
11,2.1678,0.2176,13326.48,3.69
12,2.2056,0.2358,13315.44,3.69
13,2.0272,0.2570,13339.52,3.68
14,2.0364,0.2800,13363.90,3.68
15,2.0481,0.2941,13360.09,3.68

# m=8, global_batch=128
epoch,train_loss,train_acc,throughput,epoch_time
1,6.1417,0.1149,1988.99,25.10
2,2.2164,0.1561,2065.73,24.17
3,2.1776,0.1720,2054.00,24.30
4,2.0959,0.1998,2067.96,24.14
5,1.9155,0.2680,2076.74,24.04
6,1.8312,0.3114,2047.38,24.38
7,1.7482,0.3546,2053.54,24.31
8,1.6794,0.3838,2058.82,24.25
9,1.6082,0.4073,2056.19,24.28
10,1.5573,0.4305,2057.20,24.27
11,1.4917,0.4580,2057.44,24.26
12,1.4274,0.4836,2055.78,24.28
13,1.3634,0.5126,2045.09,24.41
14,1.3057,0.5367,2061.00,24.22
15,1.2551,0.5565,2089.44,23.89

# m=8, global_batch=256
epoch,train_loss,train_acc,throughput,epoch_time
1,9.6009,0.1295,3885.41,12.85
2,2.2513,0.1549,4041.96,12.35
3,2.2303,0.1639,4034.16,12.37
4,2.2021,0.1769,4016.29,12.43
5,2.1562,0.1998,4048.53,12.33
6,2.1120,0.2222,4035.78,12.37
7,2.0593,0.2446,4058.51,12.30
8,2.0079,0.2653,4013.85,12.44
9,1.9174,0.2978,4019.91,12.42
10,1.7935,0.3381,4021.47,12.41
11,1.7114,0.3721,3920.05,12.73
12,1.6594,0.3938,4038.03,12.36
13,1.6155,0.4109,4047.94,12.33
14,1.5889,0.4146,4078.84,12.24
15,1.5481,0.4354,4067.62,12.27

# m=8, global_batch=512
epoch,train_loss,train_acc,throughput,epoch_time
1,9.2476,0.1017,5612.70,8.85
2,2.9294,0.1183,5879.10,8.45
3,2.4794,0.1604,5865.96,8.47
4,2.1758,0.1830,5888.01,8.43
5,2.0772,0.2061,5878.74,8.45
6,2.0093,0.2324,5896.65,8.42
7,1.9651,0.2530,5871.18,8.46
8,1.9001,0.2860,5902.11,8.41
9,1.8092,0.3184,5891.05,8.43
10,1.7406,0.3463,5891.87,8.43
11,1.6937,0.3692,5919.32,8.39
12,1.6426,0.3907,5893.97,8.43
13,1.5921,0.4115,5893.98,8.43
14,1.5493,0.4314,5889.12,8.43
15,1.4972,0.4515,5868.13,8.46

# m=8, global_batch=1024
epoch,train_loss,train_acc,throughput,epoch_time
1,9.6260,0.1127,7180.74,6.84
2,4.1009,0.1409,7556.92,6.50
3,3.0601,0.1771,7569.65,6.49
4,2.6582,0.1875,7616.18,6.45
5,2.4057,0.2193,7580.27,6.48
6,2.2163,0.2650,7588.77,6.48
7,2.1223,0.2886,7590.13,6.48
8,1.9651,0.3048,7534.12,6.52
9,1.8544,0.3304,7601.16,6.47
10,2.0479,0.3137,7609.51,6.46
11,1.8490,0.3522,7582.21,6.48
12,1.7347,0.3766,7540.43,6.52
13,1.6875,0.3939,7580.15,6.48
14,1.6359,0.4126,7572.16,6.49
15,1.5866,0.4268,7596.61,6.47

# m=8, global_batch=2048
epoch,train_loss,train_acc,throughput,epoch_time
1,12.6154,0.1050,7453.30,6.59
2,3.9621,0.1074,8474.98,5.80
3,2.5944,0.1404,8527.58,5.76
4,2.3800,0.1756,8418.07,5.84
5,2.2518,0.1932,8463.10,5.81
6,2.1944,0.2066,8521.04,5.77
7,2.2016,0.2130,8488.38,5.79
8,2.1296,0.2242,8507.81,5.78
9,2.1601,0.2305,8448.94,5.82
10,2.0631,0.2446,8453.31,5.81
11,2.0537,0.2542,8439.99,5.82
12,1.9962,0.2615,8487.42,5.79
13,1.9691,0.2701,8470.30,5.80
14,1.9470,0.2817,8437.01,5.83
15,1.8938,0.2920,8481.72,5.80
